{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de58db82",
   "metadata": {},
   "source": [
    "<h1> db_score_3_labels.xlsx을 mysql의 테이블로 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "aa02a4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysql의 테이블로 구축 완료\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "def load_dbscore_data():\n",
    "    xl_file = 'db_score_3_labels.xlsx'\n",
    "    db_score = pd.read_excel(xl_file)\n",
    "\n",
    "    conn = pymysql.connect(host='localhost', user='june', password='wnsgur97895', db='datascience')\n",
    "    curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "        \n",
    "    drop_sql = \"\"\"drop table if exists db_score \"\"\"\n",
    "    curs.execute(drop_sql)\n",
    "    conn.commit()\n",
    "    \n",
    "    import sqlalchemy\n",
    "    database_username = 'june'\n",
    "    database_password = 'wnsgur97895'\n",
    "    database_ip       = 'localhost'\n",
    "    database_name     = 'datascience'\n",
    "    database_connection = sqlalchemy.create_engine('mysql+pymysql://{0}:{1}@{2}/{3}'.\n",
    "                                                   format(database_username, database_password, \n",
    "                                                          database_ip, database_name))\n",
    "    db_score.to_sql(con=database_connection, name='db_score', if_exists='replace')\n",
    "\n",
    "load_dbscore_data()\n",
    "print(\"mysql의 테이블로 구축 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea83170",
   "metadata": {},
   "source": [
    "<h1>grade B에 대한 SVM binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "31699c56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================SVM binary classification(kernel ='rbf', C=100000.0) train_test_split의 경우===================\n",
      "train데이터 개수 : 68\n",
      "test데이터 개수 : 24\n",
      "accuracy=0.833333\n",
      "precision=0.666667\n",
      "recall=0.857143\n",
      "f1_score=0.750000\n",
      "\n",
      "====================SVM binary classification(kernal = 'rbf', C=100.0) 15-fold cross validation의 경우================\n",
      "average_accuracy =0.695238\n",
      "average_precision =0.527778\n",
      "average_recall =0.700000\n",
      "average_f1_score =0.568571\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def classification_performance_eval(y, y_predict):\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    \n",
    "    for y, yp in zip(y,y_predict):\n",
    "        if y == 1 and yp == 1:\n",
    "            tp += 1\n",
    "        elif y == 1 and yp == -1:\n",
    "            fn += 1\n",
    "        elif y == -1 and yp == 1:\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    #print(\"===============================\")        \n",
    "    #print(\"tp : \" + str(tp))\n",
    "    #print(\"tn : \" + str(tn))        \n",
    "    #print(\"fp : \" + str(fp))        \n",
    "    #print(\"fn : \" + str(fn))        \n",
    "    #print(\"===============================\")        \n",
    "        \n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    \n",
    "    precision = (tp)/(tp+fp) if ((tp+fp) != 0) else 0\n",
    "    recall = (tp)/(tp+fn) if ((tp+fn) != 0) else 0\n",
    "    f1_score = 2*precision*recall / (precision+recall) if ((precision+recall) != 0) else 0\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "\n",
    "conn = pymysql.connect(host='localhost', user='june', password='wnsgur97895', db='datascience')\n",
    "curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "sql = \"select * from db_score\"\n",
    "curs.execute(sql)\n",
    "\n",
    "data  = curs.fetchall()\n",
    "\n",
    "#print(data)\n",
    "\n",
    "curs.close()\n",
    "conn.close()\n",
    "\n",
    "#db_score의 feature variable\n",
    "X = [ (t['homework'], t['discussion'], t['final']) for t in data ]\n",
    "X = np.array(X)\n",
    "\n",
    "#db_score의 label attribute\n",
    "y = [ 1 if (t['grade'] == 'B') else -1 for t in data ]\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "#train_test_split의 경우\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.26, random_state=42)\n",
    "\n",
    "#SVM import\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "kernelName = 'rbf'\n",
    "\n",
    "cNum1 =1e5\n",
    "\n",
    "svm = SVC(kernel = kernelName, C= int(cNum1))\n",
    "\n",
    "svm = svm.fit(X_train, y_train)\n",
    "\n",
    "y_predict = svm.predict(X_test)\n",
    "\n",
    "acc, prec, rec, f1 = classification_performance_eval(y_test, y_predict)\n",
    "\n",
    "#print(X_test)\n",
    "\n",
    "print(\"====================SVM binary classification(kernel ='\"+kernelName+\"', C=\"+str(cNum1)+\") train_test_split의 경우===================\")\n",
    "print(\"train데이터 개수 : \"+str(len(X_train)) )\n",
    "print(\"test데이터 개수 : \"+str(len(X_test)) )\n",
    "print(\"accuracy=%f\" %acc)\n",
    "print(\"precision=%f\" %prec)\n",
    "print(\"recall=%f\" %rec)\n",
    "print(\"f1_score=%f\" %f1)\n",
    "\n",
    "#K-fold cross validation의 경우\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "\n",
    "kNum2 = 15   #데이트를 kNum 등분해서 교차검증\n",
    "cNum2 = 1e2  #SVC C값\n",
    "\n",
    "kf = KFold(n_splits= int(kNum2), random_state=42, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train2, X_test2 = X[train_index], X[test_index]\n",
    "    y_train2, y_test2 = y[train_index], y[test_index]\n",
    "    \n",
    "    svm2 = SVC(kernel = 'rbf' , C=int(cNum2))\n",
    "    svm2 = svm2.fit(X_train2, y_train2)\n",
    "    y_predict2 = svm2.predict(X_test2)\n",
    "    acc, prec, rec, f1 = classification_performance_eval(y_test2, y_predict2)\n",
    "\n",
    "    accuracy.append(acc)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    f1_score.append(f1)\n",
    "\n",
    "\n",
    "   \n",
    "import statistics\n",
    "print()\n",
    "print(\"====================SVM binary classification(kernal = 'rbf', C=\"+str(cNum2)+\") \"+str(kNum2)+\"-fold cross validation의 경우================\")\n",
    "\n",
    "print(\"average_accuracy =%f\"%statistics.mean(accuracy))\n",
    "print(\"average_precision =%f\"%statistics.mean(precision))\n",
    "print(\"average_recall =%f\"%statistics.mean(recall))\n",
    "print(\"average_f1_score =%f\"%statistics.mean(f1_score))\n",
    "\n",
    "#from sklearn.metrics import classification_report\n",
    "#print(classification_report(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3863b1",
   "metadata": {},
   "source": [
    "<h1>grade B에 대한 Logistic Regression 알고리즘의 binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "431370ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Logistic Regression binary classification(C=1) train_test_split의 경우===================\n",
      "train데이터 개수 : 80\n",
      "test데이터 개수 : 12\n",
      "accuracy=0.583333\n",
      "precision=0.500000\n",
      "recall=0.800000\n",
      "f1_score=0.615385\n",
      "====================Logistic Regression binary classification(C=1) 23-fold cross validation의 경우================\n",
      "average_accuracy =0.673913\n",
      "average_precision =0.666667\n",
      "average_recall =0.695652\n",
      "average_f1_score =0.666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#db_score의 feature variable\n",
    "X = [ (t['homework'], t['discussion'], t['final']) for t in data ]\n",
    "X = np.array(X)\n",
    "\n",
    "#db_score의 label attribute\n",
    "y = [ 1 if (t['grade'] == 'B') else -1 for t in data ]\n",
    "y = np.array(y)\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "#X = scaler.fit_transform(X)\n",
    "#train_test_split의 경우\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.12, random_state=42)\n",
    "\n",
    "#스케일러 생성 => 각 feature들의 스케일을 맞추어 줘야함\n",
    "#각 feature의 평균을 0, 표준편차를 1로 맞춰줌\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "cNum3 = 1\n",
    "\n",
    "lr = LogisticRegression(C= int(cNum3),class_weight='balanced', random_state=42)\n",
    "\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "lr_y_predict = lr.predict(X_test_scaled)\n",
    "\n",
    "lr_acc, lr_prec, lr_rec, lr_f1 = classification_performance_eval(y_test, lr_y_predict)\n",
    "\n",
    "print(\"====================Logistic Regression binary classification(C=\"+str(cNum3)+\") train_test_split의 경우===================\")\n",
    "print(\"train데이터 개수 : \"+str(len(X_train)) )\n",
    "print(\"test데이터 개수 : \"+str(len(X_test_scaled)) )\n",
    "print(\"accuracy=%f\" %lr_acc)\n",
    "print(\"precision=%f\" %lr_prec)\n",
    "print(\"recall=%f\" %lr_rec)\n",
    "print(\"f1_score=%f\" %lr_f1)\n",
    "\n",
    "#print('테스트 셋 관측 수 : ' + str(len(y)) )\n",
    "#print('오분류 관측 수 : ', sum(lr_y_predict != y_test))\n",
    "\n",
    "#K-fold cross validation의 경우\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "l_accuracy = []\n",
    "l_precision = []\n",
    "l_recall = []\n",
    "l_f1_score = []\n",
    "\n",
    "kNum3 = 23  #데이트를 kNum 등분해서 교차검증\n",
    "cNum3 = 1 #SVC C값\n",
    "\n",
    "kf = KFold(n_splits= int(kNum3), random_state=42, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train2, X_test2 = X[train_index], X[test_index]\n",
    "    y_train2, y_test2 = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train2_scaled = scaler.fit_transform(X_train2)\n",
    "    X_test2_scaled = scaler.fit_transform(X_test2)\n",
    "    \n",
    "    lr = LogisticRegression(C= int(cNum3), class_weight='balanced', random_state=42)\n",
    "    lr.fit(X_train2_scaled, y_train2)\n",
    "    lr_y_predict = lr.predict(X_test2_scaled)\n",
    "    lr_acc, lr_prec, lr_rec, lr_f1 = classification_performance_eval(y_test, lr_y_predict)\n",
    "\n",
    "    l_accuracy.append(lr_acc)\n",
    "    l_precision.append(lr_prec)\n",
    "    l_recall.append(lr_rec)\n",
    "    l_f1_score.append(lr_f1)\n",
    "    \n",
    "import statistics\n",
    "\n",
    "\n",
    "print(\"====================Logistic Regression binary classification(C=\"+str(cNum3)+\") \"+str(kNum3)+\"-fold cross validation의 경우================\")\n",
    "print(\"average_accuracy =%f\"%statistics.mean(l_accuracy))\n",
    "print(\"average_precision =%f\"%statistics.mean(l_precision))\n",
    "print(\"average_recall =%f\"%statistics.mean(l_recall))\n",
    "print(\"average_f1_score =%f\"%statistics.mean(l_f1_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a422e107",
   "metadata": {},
   "source": [
    "<h1>grade A,B,C에 대한 SVM multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "bc32e58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================SVM multi-class classification(kernel ='rbf', C=5) train_test_split의 경우===================\n",
      "train데이터 개수 : 68\n",
      "test데이터 개수 : 24\n",
      "accuracy=0.791667\n",
      "\n",
      "precision(A)=0.900000\n",
      "recall(A)=1.000000\n",
      "f1_score(A)=0.947368\n",
      "\n",
      "precision(B)=0.625000\n",
      "recall(B)=0.714286\n",
      "f1_score(B)=0.666667\n",
      "\n",
      "precision(C)=0.833333\n",
      "recall(C)=0.625000\n",
      "f1_score(C)=0.714286\n",
      "\n",
      "====================SVM multi-classification(kernal = 'rbf', C=50) 3-fold cross validation의 경우================\n",
      "average_accuracy =0.695341\n",
      "\n",
      "average_precision(A) =0.786325\n",
      "average_recall(A) =0.713203\n",
      "average_f1_score(A) =0.745128\n",
      "\n",
      "average_precision(B) =0.560847\n",
      "average_recall(B) =0.599327\n",
      "average_f1_score(B) =0.565217\n",
      "\n",
      "average_precision(C) =0.758333\n",
      "average_recall(C) =0.767677\n",
      "average_f1_score(C) =0.752513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def multi_classification_performance_eval(y, y_predict):\n",
    "    \n",
    "    arr = np.zeros((3,3)) #3x3배열 생성\n",
    "    \n",
    "    for y, yp in zip(y,y_predict):\n",
    "        if y == 0 and yp == 0:\n",
    "            arr[0,0] += 1\n",
    "        elif y == 0 and yp == 1:\n",
    "            arr[1,0] += 1\n",
    "        elif y == 0 and yp == 2:\n",
    "            arr[2,0] += 1\n",
    "        elif y == 1 and yp == 0: \n",
    "            arr[0,1] += 1\n",
    "        elif y == 1 and yp == 1:\n",
    "            arr[1,1] += 1\n",
    "        elif y == 1 and yp == 2:\n",
    "            arr[2,1] += 1\n",
    "        elif y == 2 and yp == 0: \n",
    "            arr[0,2] += 1\n",
    "        elif y == 2 and yp == 1:\n",
    "            arr[1,2] += 1\n",
    "        elif y == 2 and yp == 2:\n",
    "            arr[2,2] += 1\n",
    "        \n",
    "    accuracy = (arr[0,0] + arr[1,1] + arr[2,2]) / ( arr.sum() )\n",
    "\n",
    "    precision0 = arr[0,0]/(arr[0,0]+arr[0,1]+arr[0,2]) if ((arr[0,0]+arr[0,1]+arr[0,2]) != 0) else 0\n",
    "    recall0 = arr[0,0]/(arr[0,0] + arr[1,0] + arr[2,0]) if ((arr[0,0] + arr[1,0] + arr[2,0]) != 0) else 0\n",
    "    f1_score0 = 2*precision0*recall0 / (precision0+recall0) if ((precision0+recall0) != 0) else 0\n",
    "    \n",
    "    precision1 = arr[1,1]/(arr[1,0]+arr[1,1]+arr[1,2]) if ((arr[1,0]+arr[1,1]+arr[1,2]) != 0) else 0\n",
    "    recall1 = arr[1,1]/(arr[1,1] + arr[0,1] + arr[2,1]) if ((arr[1,1] + arr[0,1] + arr[2,1]) != 0) else 0\n",
    "    f1_score1 = 2*precision1*recall1 / (precision1+recall1) if ((precision1+recall1) != 0) else 0\n",
    "    \n",
    "    precision2 = arr[2,2]/(arr[2,0]+arr[2,1]+arr[2,2]) if ((arr[2,0]+arr[2,1]+arr[2,2]) != 0) else 0\n",
    "    recall2 = arr[2,2]/(arr[0,2] + arr[1,2] + arr[2,2]) if ((arr[0,2] + arr[1,2] + arr[2,2]) != 0) else 0\n",
    "    f1_score2 = 2*precision2*recall2 / (precision2+recall2) if ((precision2+recall2) != 0) else 0\n",
    "    \n",
    "    precision = [precision0, precision1, precision2]\n",
    "    recall = [recall0, recall1, recall2]\n",
    "    f1_score = [f1_score0, f1_score1, f1_score2]\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "#db_score의 feature variable\n",
    "X = [ (t['homework'], t['discussion'], t['final']) for t in data ]\n",
    "X = np.array(X)\n",
    "\n",
    "#db_score의 label attribute\n",
    "y = []\n",
    "for t in data:\n",
    "    if(t['grade'] == 'A'):\n",
    "        y.append(0)\n",
    "    elif(t['grade'] == 'B'):\n",
    "        y.append(1)\n",
    "    else: #t['grade'] = C 인 경우\n",
    "        y.append(2)\n",
    "y = np.array(y)\n",
    "\n",
    "#train_test_split의 경우\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.26, random_state=42)\n",
    "\n",
    "#SVM import\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "kernelName = 'rbf'\n",
    "\n",
    "cNum1 =5\n",
    "\n",
    "svm = SVC(kernel = kernelName, C= int(cNum1))\n",
    "\n",
    "svm = svm.fit(X_train, y_train)\n",
    "\n",
    "y_predict = svm.predict(X_test)\n",
    "\n",
    "acc, precList, recList, f1List = multi_classification_performance_eval(y_test, y_predict)\n",
    "\n",
    "#print(X_test)\n",
    "\n",
    "print(\"====================SVM multi-class classification(kernel ='\"+kernelName+\"', C=\"+str(cNum1)+\") train_test_split의 경우===================\")\n",
    "print(\"train데이터 개수 : \"+str(len(X_train)) )\n",
    "print(\"test데이터 개수 : \"+str(len(X_test)) )\n",
    "print(\"accuracy=%f\" %acc)\n",
    "print()\n",
    "print(\"precision(A)=%f\" %precList[0])\n",
    "print(\"recall(A)=%f\" %recList[0])\n",
    "print(\"f1_score(A)=%f\" %f1List[0])\n",
    "print()\n",
    "print(\"precision(B)=%f\" %precList[1])\n",
    "print(\"recall(B)=%f\" %recList[1])\n",
    "print(\"f1_score(B)=%f\" %f1List[1])\n",
    "print()\n",
    "print(\"precision(C)=%f\" %precList[2])\n",
    "print(\"recall(C)=%f\" %recList[2])\n",
    "print(\"f1_score(C)=%f\" %f1List[2])\n",
    "\n",
    "#K-fold cross validation의 경우\n",
    "#db_score의 feature variable\n",
    "X = [ (t['homework'], t['discussion'], t['final']) for t in data ]\n",
    "X = np.array(X)\n",
    "\n",
    "#db_score의 label attribute\n",
    "y = []\n",
    "for t in data:\n",
    "    if(t['grade'] == 'A'):\n",
    "        y.append(0)\n",
    "    elif(t['grade'] == 'B'):\n",
    "        y.append(1)\n",
    "    else: #t['grade'] = C 인 경우\n",
    "        y.append(2)\n",
    "y = np.array(y)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "accuracy = []\n",
    "A_precision = []\n",
    "A_recall = []\n",
    "A_f1_score = []\n",
    "B_precision = []\n",
    "B_recall = []\n",
    "B_f1_score = []\n",
    "C_precision = []\n",
    "C_recall = []\n",
    "C_f1_score = []\n",
    "\n",
    "kNum2 =3  #데이트를 kNum 등분해서 교차검증\n",
    "cNum2 = 50  #SVC C값\n",
    "\n",
    "kf = KFold(n_splits= int(kNum2), random_state=42, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train2, X_test2 = X[train_index], X[test_index]\n",
    "    y_train2, y_test2 = y[train_index], y[test_index]\n",
    "    \n",
    "    svm2 = SVC(kernel = 'rbf' , C=int(cNum2))\n",
    "    svm2 = svm2.fit(X_train2, y_train2)\n",
    "    y_predict2 = svm2.predict(X_test2)\n",
    "\n",
    "    accuracy.append(accuracy_score(y_test2, y_predict2))\n",
    "    \n",
    "    A_precision.append(precision_score(y_test2, y_predict2, average = None)[0])\n",
    "    A_recall.append(recall_score(y_test2, y_predict2, average = None)[0])\n",
    "    A_f1_score.append(f1_score(y_test2, y_predict2, average = None)[0])\n",
    "    \n",
    "    B_precision.append(precision_score(y_test2, y_predict2, average = None)[1])\n",
    "    B_recall.append(recall_score(y_test2, y_predict2, average = None)[1])\n",
    "    B_f1_score.append(f1_score(y_test2, y_predict2, average = None)[1])\n",
    "    \n",
    "    C_precision.append(precision_score(y_test2, y_predict2, average = None)[2])\n",
    "    C_recall.append(recall_score(y_test2, y_predict2, average = None)[2])\n",
    "    C_f1_score.append(f1_score(y_test2, y_predict2, average = None)[2])\n",
    "\n",
    "\n",
    "   \n",
    "import statistics\n",
    "print()\n",
    "print(\"====================SVM multi-classification(kernal = 'rbf', C=\"+str(cNum2)+\") \"+str(kNum2)+\"-fold cross validation의 경우================\")\n",
    "\n",
    "print(\"average_accuracy =%f\"%statistics.mean(accuracy))\n",
    "print()\n",
    "print(\"average_precision(A) =%f\"%statistics.mean(A_precision))\n",
    "print(\"average_recall(A) =%f\"%statistics.mean(A_recall))\n",
    "print(\"average_f1_score(A) =%f\"%statistics.mean(A_f1_score))\n",
    "print()\n",
    "print(\"average_precision(B) =%f\"%statistics.mean(B_precision))\n",
    "print(\"average_recall(B) =%f\"%statistics.mean(B_recall))\n",
    "print(\"average_f1_score(B) =%f\"%statistics.mean(B_f1_score))\n",
    "print()\n",
    "print(\"average_precision(C) =%f\"%statistics.mean(C_precision))\n",
    "print(\"average_recall(C) =%f\"%statistics.mean(C_recall))\n",
    "print(\"average_f1_score(C) =%f\"%statistics.mean(C_f1_score))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f0698",
   "metadata": {},
   "source": [
    "<h1>grade A,B,C에 대한 Logistic Regression multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "fd805c70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Logistic Regression multi classification(C=1) train_test_split의 경우===================\n",
      "train데이터 개수 : 68\n",
      "test데이터 개수 : 24\n",
      "accuracy=0.791667\n",
      "\n",
      "precision(A)=1.000000\n",
      "recall(A)=0.777778\n",
      "f1_score(A)=0.875000\n",
      "\n",
      "precision(B)=0.625000\n",
      "recall(B)=0.714286\n",
      "f1_score(B)=0.666667\n",
      "\n",
      "precision(C)=0.777778\n",
      "recall(C)=0.875000\n",
      "f1_score(C)=0.823529\n",
      "\n",
      "====================Logistic Regression multi classification(C=1) 4-fold cross validation의 경우================\n",
      "average_accuracy =0.683096\n",
      "\n",
      "average_precision of A =0.722403\n",
      "average_recall of A =0.787302\n",
      "average_f1_score of A =0.742544\n",
      "\n",
      "average_precision of B =0.538393\n",
      "average_recall of B =0.520833\n",
      "average_f1_score of B =0.517666\n",
      "\n",
      "average_precision of C =0.809091\n",
      "average_recall of C =0.694444\n",
      "average_f1_score of C =0.717735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#db_score의 feature variable\n",
    "X = [ (t['homework'], t['discussion'], t['final']) for t in data ]\n",
    "X = np.array(X)\n",
    "\n",
    "#db_score의 label attribute\n",
    "y = []\n",
    "for t in data:\n",
    "    if(t['grade'] == 'A'):\n",
    "        y.append(0)\n",
    "    elif(t['grade'] == 'B'):\n",
    "        y.append(1)\n",
    "    else: #t['grade'] = C 인 경우\n",
    "        y.append(2)\n",
    "y = np.array(y)\n",
    "\n",
    "#train_test_split의 경우\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.26, random_state=42)\n",
    "\n",
    "\n",
    "#스케일러 생성 => 각 feature들의 스케일을 맞추어 줘야함\n",
    "#각 feature의 평균을 0, 표준편차를 1로 맞춰줌\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "cNum3 = 1\n",
    "\n",
    "lr = LogisticRegression(C= int(cNum3),random_state=42)\n",
    "\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "lr_y_predict = lr.predict(X_test_scaled)\n",
    "\n",
    "lr_acc, lr_precList, lr_recList, lr_f1List = multi_classification_performance_eval(y_test, lr_y_predict)\n",
    "\n",
    "\n",
    "print(\"====================Logistic Regression multi classification(C=\"+str(cNum3)+\") train_test_split의 경우===================\")\n",
    "print(\"train데이터 개수 : \"+str(len(X_train)) )\n",
    "print(\"test데이터 개수 : \"+str(len(X_test)) )\n",
    "print(\"accuracy=%f\" %lr_acc)\n",
    "print()\n",
    "print(\"precision(A)=%f\" %lr_precList[0])\n",
    "print(\"recall(A)=%f\" %lr_recList[0])\n",
    "print(\"f1_score(A)=%f\" %lr_f1List[0])\n",
    "print()\n",
    "print(\"precision(B)=%f\" %lr_precList[1])\n",
    "print(\"recall(B)=%f\" %lr_recList[1])\n",
    "print(\"f1_score(B)=%f\" %lr_f1List[1])\n",
    "print()\n",
    "print(\"precision(C)=%f\" %lr_precList[2])\n",
    "print(\"recall(C)=%f\" %lr_recList[2])\n",
    "print(\"f1_score(C)=%f\" %lr_f1List[2])\n",
    "\n",
    "#print('테스트 셋 관측 수 : ' + str(len(y)) )\n",
    "#print('오분류 관측 수 : ', sum(lr_y_predict != y_test))\n",
    "\n",
    "#K-fold cross validation의 경우\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "l_accuracy = []\n",
    "\n",
    "l_A_precision = []\n",
    "l_A_recall = []\n",
    "l_A_f1_score = []\n",
    "l_B_precision = []\n",
    "l_B_recall = []\n",
    "l_B_f1_score = []\n",
    "l_C_precision = []\n",
    "l_C_recall = []\n",
    "l_C_f1_score = []\n",
    "\n",
    "kNum3 = 4  #데이터를 kNum 등분해서 교차검증\n",
    "cNum3 = 1 #SVC C값\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "kf = KFold(n_splits= int(kNum3), random_state=42, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train2, X_test2 = X[train_index], X[test_index]\n",
    "    y_train2, y_test2 = y[train_index], y[test_index]\n",
    "    \n",
    "    #X_train2_scaled = scaler.fit_transform(X_train2)\n",
    "    #X_test2_scaled = scaler.fit_transform(X_test2)\n",
    "    \n",
    "    lr = LogisticRegression(C= int(cNum3), class_weight = 'balanced',random_state=42)\n",
    "    lr.fit(X_train2, y_train2)\n",
    "    lr_y_predict = lr.predict(X_test2)\n",
    "    #print(\"===============실제============\")\n",
    "    #print(y_test2)\n",
    "    #print(\"===============예측============\")\n",
    "    #print(lr_y_predict)\n",
    "    l_accuracy.append(acc)\n",
    "\n",
    "    accuracy.append(accuracy_score(y_test2, lr_y_predict))\n",
    "    l_A_precision.append(precision_score(y_test2, lr_y_predict, average = None)[0])\n",
    "    l_A_recall.append(recall_score(y_test2, lr_y_predict, average = None)[0])\n",
    "    l_A_f1_score.append(f1_score(y_test2, lr_y_predict, average = None)[0])\n",
    "    \n",
    "    l_B_precision.append(precision_score(y_test2, lr_y_predict, average = None)[1])\n",
    "    l_B_recall.append(recall_score(y_test2, lr_y_predict, average = None)[1])\n",
    "    l_B_f1_score.append(f1_score(y_test2, lr_y_predict, average = None)[1])\n",
    "    \n",
    "    l_C_precision.append(precision_score(y_test2, lr_y_predict, average = None)[2])\n",
    "    l_C_recall.append(recall_score(y_test2, lr_y_predict, average = None)[2])\n",
    "    l_C_f1_score.append(f1_score(y_test2, lr_y_predict, average = None)[2])\n",
    "    \n",
    "import statistics\n",
    "print()\n",
    "\n",
    "print(\"====================Logistic Regression multi classification(C=\"+str(cNum3)+\") \"+str(kNum3)+\"-fold cross validation의 경우================\")\n",
    "print(\"average_accuracy =%f\"%statistics.mean(accuracy))\n",
    "print()\n",
    "print(\"average_precision of A =%f\"%statistics.mean(l_A_precision))\n",
    "print(\"average_recall of A =%f\"%statistics.mean(l_A_recall))\n",
    "print(\"average_f1_score of A =%f\"%statistics.mean(l_A_f1_score))\n",
    "print()\n",
    "\n",
    "print(\"average_precision of B =%f\"%statistics.mean(l_B_precision))\n",
    "print(\"average_recall of B =%f\"%statistics.mean(l_B_recall))\n",
    "print(\"average_f1_score of B =%f\"%statistics.mean(l_B_f1_score))\n",
    "print()\n",
    "\n",
    "print(\"average_precision of C =%f\"%statistics.mean(l_C_precision))\n",
    "print(\"average_recall of C =%f\"%statistics.mean(l_C_recall))\n",
    "print(\"average_f1_score of C =%f\"%statistics.mean(l_C_f1_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ea290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f5ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
